# zhihuuser
scrapy+mongodb爬取知乎所有用户的信息

思路分析：
每个人都有关注列表和粉丝列表，尤其对于大V来说，粉丝和关注尤其更多。
如果我们从一个大V开始，首先可以获取他的个人信息，然后我们获取他的粉丝列表和关注列表，
然后遍历列表中的每一个用户，进一步抓取每一个用户的信息还有他们各自的粉丝列表和关注列表，
然后再进一步遍历获取到的列表中的每一个用户，进一步抓取他们的信息和关注粉丝列表，循环往复，不断递归，
这样就可以做到一爬百，百爬万，万爬百万，通过社交关系自然形成了一个爬取网，这样就可以爬到所有的用户信息了。
当然零粉丝零关注的用户就忽略他们吧
